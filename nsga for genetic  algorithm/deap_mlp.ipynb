{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:46.405600400Z",
     "start_time": "2024-10-31T07:09:39.991491300Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyBeamSim\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.optim as optim\n",
    "from model.old_old_model import Model, Model2, MLP\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from deap import base, creator, tools, algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      drift1_len  quad1_len  quad1_gra  drift2_len  quad2_len  quad2_gra  \\\n0       0.402310   0.450841 -16.332723    0.170125   0.213844   7.026671   \n1       0.237463   0.454075  14.937412    0.273825   0.334553   5.617945   \n2       0.414345   0.177982  19.552067    0.388376   0.442580   2.004069   \n3       0.246283   0.124380   0.320149    0.130190   0.210073  13.761691   \n4       0.256067   0.194462   6.097415    0.473669   0.432795   7.627331   \n...          ...        ...        ...         ...        ...        ...   \n9995    0.247073   0.286787   2.478341    0.375353   0.320700 -13.608154   \n9996    0.407613   0.432325   4.456587    0.302943   0.444821   4.182542   \n9997    0.148527   0.189331  10.690400    0.205502   0.385139   9.790066   \n9998    0.307523   0.318801   2.121998    0.348172   0.262224 -10.475280   \n9999    0.166128   0.248988  -2.887280    0.361308   0.429047  14.610668   \n\n        x_sig4    y_sig4  \n0     0.011611  0.012997  \n1     0.004942  0.007303  \n2     0.004739  0.004655  \n3     0.003692  0.013368  \n4     0.001405  0.006946  \n...        ...       ...  \n9995  0.011704  0.003130  \n9996  0.003308  0.008749  \n9997  0.001836  0.007299  \n9998  0.014424  0.003703  \n9999  0.005579  0.006105  \n\n[10000 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>drift1_len</th>\n      <th>quad1_len</th>\n      <th>quad1_gra</th>\n      <th>drift2_len</th>\n      <th>quad2_len</th>\n      <th>quad2_gra</th>\n      <th>x_sig4</th>\n      <th>y_sig4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.402310</td>\n      <td>0.450841</td>\n      <td>-16.332723</td>\n      <td>0.170125</td>\n      <td>0.213844</td>\n      <td>7.026671</td>\n      <td>0.011611</td>\n      <td>0.012997</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.237463</td>\n      <td>0.454075</td>\n      <td>14.937412</td>\n      <td>0.273825</td>\n      <td>0.334553</td>\n      <td>5.617945</td>\n      <td>0.004942</td>\n      <td>0.007303</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.414345</td>\n      <td>0.177982</td>\n      <td>19.552067</td>\n      <td>0.388376</td>\n      <td>0.442580</td>\n      <td>2.004069</td>\n      <td>0.004739</td>\n      <td>0.004655</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.246283</td>\n      <td>0.124380</td>\n      <td>0.320149</td>\n      <td>0.130190</td>\n      <td>0.210073</td>\n      <td>13.761691</td>\n      <td>0.003692</td>\n      <td>0.013368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.256067</td>\n      <td>0.194462</td>\n      <td>6.097415</td>\n      <td>0.473669</td>\n      <td>0.432795</td>\n      <td>7.627331</td>\n      <td>0.001405</td>\n      <td>0.006946</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>0.247073</td>\n      <td>0.286787</td>\n      <td>2.478341</td>\n      <td>0.375353</td>\n      <td>0.320700</td>\n      <td>-13.608154</td>\n      <td>0.011704</td>\n      <td>0.003130</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>0.407613</td>\n      <td>0.432325</td>\n      <td>4.456587</td>\n      <td>0.302943</td>\n      <td>0.444821</td>\n      <td>4.182542</td>\n      <td>0.003308</td>\n      <td>0.008749</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>0.148527</td>\n      <td>0.189331</td>\n      <td>10.690400</td>\n      <td>0.205502</td>\n      <td>0.385139</td>\n      <td>9.790066</td>\n      <td>0.001836</td>\n      <td>0.007299</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>0.307523</td>\n      <td>0.318801</td>\n      <td>2.121998</td>\n      <td>0.348172</td>\n      <td>0.262224</td>\n      <td>-10.475280</td>\n      <td>0.014424</td>\n      <td>0.003703</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>0.166128</td>\n      <td>0.248988</td>\n      <td>-2.887280</td>\n      <td>0.361308</td>\n      <td>0.429047</td>\n      <td>14.610668</td>\n      <td>0.005579</td>\n      <td>0.006105</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/mlp_10000.csv', index_col=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:46.491134800Z",
     "start_time": "2024-10-31T07:09:46.407612800Z"
    }
   },
   "id": "f13a4d3c6e041e10"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "ref_energy = 5\n",
    "num_particle = 102400\n",
    "simulator = pyBeamSim.BeamSimulator()\n",
    "simulator.init_beam(num_particle, 938.272046, 1.0, 0.0)\n",
    "# key step\n",
    "simulator.init_Beamline()\n",
    "simulator.set_beamTwiss(0, 0.003, 0.0001, 0, 0.003, 0.0001, 0, 8, 3.1415926e-11, 0, ref_energy, 500, 1)\n",
    "simulator.UpdateBeamParameters()\n",
    "\n",
    "def simulate_by_seq(simulator, value_list):\n",
    "    simulator.init_Beamline()\n",
    "    simulator.add_Drift('drift1', value_list[0], Aperture=0.05)\n",
    "    simulator.add_Quad('quad1', value_list[1], Aperture=0.012, FieldGradient=value_list[2])\n",
    "    simulator.add_Drift('drift2', value_list[3], Aperture=0.05)\n",
    "    simulator.add_Quad('quad2', value_list[4], Aperture=0.028, FieldGradient=value_list[5])\n",
    "    simulator.simulate_all()\n",
    "    simulator.UpdateBeamParameters()\n",
    "    x_sig = simulator.getSigX()\n",
    "    y_sig = simulator.getSigY()\n",
    "    return x_sig, y_sig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:46.512605600Z",
     "start_time": "2024-10-31T07:09:46.488133900Z"
    }
   },
   "id": "32ff30b7fecdf92b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.0005616418695696335, 0.0008292177069427745)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f= [0.237463,0.454075,14.937412,0.273825,0.334553,5.617945]\n",
    "simulate_by_seq(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:46.900007400Z",
     "start_time": "2024-10-31T07:09:46.499619700Z"
    }
   },
   "id": "e68a18762b75c6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'front' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m a,b \u001B[38;5;241m=\u001B[39m simulate_by_seq(\u001B[43mfront\u001B[49m[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(a,b,\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(front[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mfitness\u001B[38;5;241m.\u001B[39mvalues, \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'front' is not defined"
     ]
    }
   ],
   "source": [
    "a,b = simulate_by_seq(front[0][0])\n",
    "print(a,b,'\\n')\n",
    "print(front[0][0].fitness.values, '\\n')\n",
    "c, d = simulate_by_seq(front[0][5])\n",
    "print(c, d)\n",
    "print(front[0][5].fitness.values, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:48.617526100Z",
     "start_time": "2024-10-31T07:09:46.900007400Z"
    }
   },
   "id": "50d0eabeaa2f1d07"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "             low  high units\ndrift1_len   0.1   0.5     m\nquad1_len    0.1   0.5     m\nquad1_gra  -20.0  20.0   T/m\ndrift2_len   0.1   0.5     m\nquad2_len    0.1   0.5     m\nquad2_gra  -20.0  20.0   T/m",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>low</th>\n      <th>high</th>\n      <th>units</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>drift1_len</th>\n      <td>0.1</td>\n      <td>0.5</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>quad1_len</th>\n      <td>0.1</td>\n      <td>0.5</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>quad1_gra</th>\n      <td>-20.0</td>\n      <td>20.0</td>\n      <td>T/m</td>\n    </tr>\n    <tr>\n      <th>drift2_len</th>\n      <td>0.1</td>\n      <td>0.5</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>quad2_len</th>\n      <td>0.1</td>\n      <td>0.5</td>\n      <td>m</td>\n    </tr>\n    <tr>\n      <th>quad2_gra</th>\n      <td>-20.0</td>\n      <td>20.0</td>\n      <td>T/m</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\" variable dataframe created\"\"\"\n",
    "vary = ['drift1_len', 'quad1_len', 'quad1_gra', 'drift2_len', 'quad2_len', 'quad2_gra']\n",
    "low = [0.1, 0.1, -20.0, 0.1, 0.1, -20.0]\n",
    "high = [0.5, 0.5, 20.0, 0.5, 0.5, 20.0]\n",
    "units = ['m', 'm', 'T/m', 'm', 'm', 'T/m']\n",
    "variable = pd.DataFrame(index=vary)\n",
    "variable['low'] = low\n",
    "variable['high'] = high\n",
    "variable['units'] = units\n",
    "variable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:10:01.356273700Z",
     "start_time": "2024-10-31T07:10:01.301850200Z"
    }
   },
   "id": "a1d718b68cea62d4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-2]\n",
    "y = df.iloc[:, -2:]\n",
    "X = torch.Tensor(X.values)\n",
    "y = torch.Tensor(y.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:10:02.546708200Z",
     "start_time": "2024-10-31T07:10:02.445605Z"
    }
   },
   "id": "bc9eeeb9cedf64a1"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:10:02.550718100Z",
     "start_time": "2024-10-31T07:10:02.487780800Z"
    }
   },
   "id": "760fe26673c7825c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# model:MLP(Depth: 4, Width:6-32-64-32-16-2, learning_rate: 0.001 )\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "model = nn.Sequential(nn.Linear(6, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(32, 64),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(64, 32),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(32, 16),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(16, 2),\n",
    "                    )\n",
    "\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0013, betas=(0.9, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:10:03.030389700Z",
     "start_time": "2024-10-31T07:10:02.989155600Z"
    }
   },
   "id": "23d9b65bd828b10e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dba5e9cb5cbcfba4"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def val_acc(ml, val_loader, device):\n",
    "    ml.eval()\n",
    "    total_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X_test, y_test in val_loader:\n",
    "            X_test = X_test.to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            y_pred = ml(X_test)\n",
    "            # test_criterion = nn.MSELoss(reduction='sum')\n",
    "            test_criterion = nn.L1Loss()\n",
    "            acc = test_criterion(y_pred, y_test)\n",
    "            total_acc += acc\n",
    "    return total_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:10:03.633498900Z",
     "start_time": "2024-10-31T07:10:03.611175800Z"
    }
   },
   "id": "165380357c934189"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training is using cuda\n",
      "epoch1: loss: 4.341819\n",
      "epoch2: loss: 0.982373\n",
      "epoch3: loss: 0.738598\n",
      "epoch4: loss: 0.694039\n",
      "epoch5: loss: 0.686818\n",
      "epoch6: loss: 0.674485\n",
      "epoch7: loss: 0.665541\n",
      "epoch8: loss: 0.663569\n",
      "epoch9: loss: 0.650530\n",
      "epoch10: loss: 0.644949\n",
      "epoch11: loss: 0.645172\n",
      "epoch12: loss: 0.637503\n",
      "epoch13: loss: 0.638533\n",
      "epoch14: loss: 0.632399\n",
      "epoch15: loss: 0.630358\n",
      "epoch16: loss: 0.629511\n",
      "epoch17: loss: 0.620229\n",
      "epoch18: loss: 0.608286\n",
      "epoch19: loss: 0.602227\n",
      "epoch20: loss: 0.574361\n",
      "epoch21: loss: 0.560060\n",
      "epoch22: loss: 0.539703\n",
      "epoch23: loss: 0.538190\n",
      "epoch24: loss: 0.531964\n",
      "epoch25: loss: 0.525708\n",
      "epoch26: loss: 0.517876\n",
      "epoch27: loss: 0.503357\n",
      "epoch28: loss: 0.506303\n",
      "epoch29: loss: 0.501459\n",
      "epoch30: loss: 0.493267\n",
      "epoch31: loss: 0.486050\n",
      "epoch32: loss: 0.488408\n",
      "epoch33: loss: 0.474725\n",
      "epoch34: loss: 0.469560\n",
      "epoch35: loss: 0.469140\n",
      "epoch36: loss: 0.456870\n",
      "epoch37: loss: 0.455961\n",
      "epoch38: loss: 0.451620\n",
      "epoch39: loss: 0.451670\n",
      "epoch40: loss: 0.450997\n",
      "epoch41: loss: 0.443704\n",
      "epoch42: loss: 0.440344\n",
      "epoch43: loss: 0.441655\n",
      "epoch44: loss: 0.436016\n",
      "epoch45: loss: 0.431891\n",
      "epoch46: loss: 0.436210\n",
      "epoch47: loss: 0.435615\n",
      "epoch48: loss: 0.427493\n",
      "epoch49: loss: 0.428932\n",
      "epoch50: loss: 0.423087\n"
     ]
    }
   ],
   "source": [
    "# train , if not ,just torch.load\n",
    "\n",
    "num_epochs=50\n",
    "\n",
    "losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "test_acc = val_acc(model, val_loader=test_loader, device=device)\n",
    "test_accuracies.append(test_acc.cpu().numpy())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch == 0:\n",
    "        print(f'the training is using {device}')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device) # two-dim tensor\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        total_loss += loss\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_acc = val_acc(model, val_loader=test_loader, device=device)\n",
    "    test_accuracies.append(test_acc.cpu().numpy())\n",
    "    losses.append(total_loss.cpu().detach().numpy()) # to cpu to plot\n",
    "    print(f'epoch{epoch+1}: loss: {total_loss:8f}')\n",
    "\n",
    "torch.save(model.state_dict(), '../model_save/deap_mlp.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:11:37.412626200Z",
     "start_time": "2024-10-31T07:10:04.099145100Z"
    }
   },
   "id": "48534e33edfcb995"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../model_save/deap_mlp.pth'))\n",
    "model.to('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.637095500Z"
    }
   },
   "id": "3feb79f9700fbad5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test\n",
    "x = X[0, :].to('cpu').detach()\n",
    "print(model(x))\n",
    "print(y[2, :])  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.640536500Z"
    }
   },
   "id": "3f7428c4df5fd1fc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model(torch.Tensor([0, 0, 0, 0, 0, 0])).detach().numpy()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.644074500Z"
    }
   },
   "id": "9c2edd0fa89413e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NSGA-Ⅱ"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c611bac8d113689d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for speed, occur in cpu or gpu\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def create_individual():\n",
    "    return [np.random.uniform(row['low'], row['high']) for _, row in variable.iterrows()]\n",
    "\n",
    "def evaluate(individual):\n",
    "    output = model(torch.tensor(individual)).detach().numpy()\n",
    "    return output[0], output[1]\n",
    "\n",
    "def genInd(low, high):\n",
    "    return [random.uniform(low_i, high_i) for low_i, high_i in zip(low, high)]\n",
    "# def create_individual():\n",
    "#     return [np.random.uniform(row['low'], row['high']) for _, row in variable.iterrows()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:48.648657500Z",
     "start_time": "2024-10-31T07:09:48.647489500Z"
    }
   },
   "id": "e6a41f2c40a0a5e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define question\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0))   # two min\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "low = [0.1, 0.1, -20.0, 0.1, 0.1, -20.0]\n",
    "high = [0.5, 0.5, 20.0, 0.5, 0.5, 20.0]\n",
    "n_genes = len(low)  # 6\n",
    "\n",
    "# initial individual and population\n",
    "toolbox.register('genInd',genInd,low,high)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.genInd)   # list\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=low, up=high, eta=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=low, up=high, eta=20.0, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.649675800Z"
    }
   },
   "id": "118e2b3922f4bd8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_POP = 200#种群内个体数量\n",
    "ngen = 100#迭代步数，参数过小，在收敛之前就结束搜索\n",
    "cxpb = 0.8#交叉概率，参数过小，族群不能有效更新\n",
    "mutpb = 0.2#突变概率，参数过小，容易陷入局部最优\n",
    "hof = tools.ParetoFront()\n",
    "\n",
    "population = toolbox.population(n=N_POP)\n",
    "for ind in population:\n",
    "    ind.fitness.values = toolbox.evaluate(ind)\n",
    "for gen in range(1, ngen + 1):\n",
    "\n",
    "    # 选择下一代的父母\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "\n",
    "    # 克隆选择出来的个体\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # 应用交叉和变异\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < cxpb:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < mutpb:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # 重新评估所有失效的个体\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    for ind in invalid_ind:\n",
    "        ind.fitness.values = toolbox.evaluate(ind)\n",
    "\n",
    "    # 将当前种群和后代种群合并\n",
    "    population[:] = toolbox.select(population + offspring, len(population))\n",
    "\n",
    "    # 更新 Pareto 前沿\n",
    "    hof.update(population)\n",
    "\n",
    "    # 输出当前代的最优解\n",
    "    front = tools.sortNondominated(population, len(population), first_front_only=True) # one tuple  with a list if True\n",
    "    print(f\"num in Generation {gen}: {len(front[0])}\")\n",
    "    # for ind in front[0]:\n",
    "    #     print(ind.fitness.values, ind)\n",
    "    \n",
    "# fronts = tools.emo.sortNondominated(pop,k=N_POP,first_front_only=False)#快速非支配排序，得到不同前沿的pareto层集合fronts\n",
    "# #print(fronts)#打印一个pareto层集合fronts检查，每层前沿都是一个列表\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.651668Z"
    }
   },
   "id": "696835e09596fe04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### get figure for pareto front"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f10af7b32fffa9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dots = [] # for MLP\n",
    "# true for simulator\n",
    "true_x_sig = []\n",
    "true_y_sig = []\n",
    "for inv in front[0]:\n",
    "    dots.append(inv.fitness.values)\n",
    "    x_sig, y_sig = simulate_by_seq(inv)\n",
    "    true_x_sig.append(x_sig)\n",
    "    true_y_sig.append(y_sig)\n",
    "all_x = [point[0] for point in dots]\n",
    "all_y = [point[1] for point in dots]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.654355700Z"
    }
   },
   "id": "a7b29ed58e4f30b4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.title('pareto front')\n",
    "plt.xlabel('x_sig')\n",
    "plt.ylabel(\"y_sig\")\n",
    "\n",
    "plt.scatter(all_x, all_y)\n",
    "plt.scatter(true_x_sig, true_y_sig, color='yellow', marker='x')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.656975200Z"
    }
   },
   "id": "49c44b0c477cf5e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### test for failure"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb3db7332ae4014a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for speed, occur in cpu or gpu\n",
    "\n",
    "model.to('cpu')\n",
    "model.eval()\n",
    "\n",
    "def model_predict(params):\n",
    "    with torch.no_grad():\n",
    "        return model(torch.tensor(params, dtype=torch.float32)).numpy()\n",
    "\n",
    "# define question\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "# individual\n",
    "def create_individual():\n",
    "    return [np.random.uniform(row['low'], row['high']) for _, row in variable.iterrows()]\n",
    "\n",
    "# fitness function\n",
    "def evaluate(individual):\n",
    "    output = model_predict(individual)\n",
    "    return output[0], output[1]\n",
    "\n",
    "# initial toolbox\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, create_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinary, eta=0.5)   # 交叉\n",
    "# toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.1, indpb=0.2)\n",
    "# toolbox.register(\"mutate\", tools.mutPolynomialBounded, eta=20.0, low=[row['low'] for _, row in variable.iterrows()],\n",
    "#                  up=[row['high'] for _, row in variable.iterrows()], indpb=0.2)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, eta=20.0, low=low, up=high, indpb=0.50)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# initial the population\n",
    "population = toolbox.population(n=100)\n",
    "\n",
    "NGEN = 200#迭代步数，参数过小，在收敛之前就结束搜索\n",
    "CXPB = 0.8#交叉概率，参数过小，族群不能有效更新\n",
    "MUTPB = 0.2#突变概率，参数过小，容易陷入局部最优\n",
    "\n",
    "# epoch by NSGA\n",
    "for gen in range(50): # 50 generations\n",
    "     fitnesses = list(map(toolbox.evaluate, population))\n",
    "     for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    # Selection, crossover, and mutation\n",
    "     offspring = toolbox.select(population, len(population))\n",
    "     offspring = list(map(toolbox.clone, offspring))\n",
    "     \n",
    "     for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "         if np.random.rand() < 0.5:  # 交叉概率\n",
    "             toolbox.mate(child1, child2)    #inplace \n",
    "             del child1.fitness.values  # 使适应度无效\n",
    "             del child1.fitness.values\n",
    "             \n",
    "     for mutant in offspring:\n",
    "         if np.random.rand() < 0.2:  # 变异概率\n",
    "             toolbox.mutate(mutant)\n",
    "             del mutant.fitness.values  # 使适应度无效\n",
    "\n",
    "     # 更新种群\n",
    "     population[:] = offspring\n",
    "     \n",
    "fits = [ind.fitness.values for ind in population]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T07:09:48.720603Z",
     "start_time": "2024-10-31T07:09:48.658984Z"
    }
   },
   "id": "4221100dabbf91a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population = toolbox.population(n=10)\n",
    "fitnesses = list(map(toolbox.evaluate, population))\n",
    "fitnesses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.661501300Z"
    }
   },
   "id": "4c7a25d1c42013e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population = toolbox.population(n=100)\n",
    "fitnesses = list(map(toolbox.evaluate, population))\n",
    "for ind, fit in zip(population, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "    # Selection, crossover, and mutation\n",
    "offspring = toolbox.select(population, len(population))\n",
    "offspring = list(map(toolbox.clone, offspring))\n",
    "for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "    if np.random.rand() < 0.5:  # 交叉概率\n",
    "        toolbox.mate(child1, child2)\n",
    "        del child1.fitness.values  # 使适应度无效\n",
    "for mutant in offspring:\n",
    "    if np.random.rand() < 0.2:  # 变异概率\n",
    "        toolbox.mutate(mutant)\n",
    "        del mutant.fitness.values  # 使适应度无效"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.664019900Z"
    }
   },
   "id": "d2644eabce8cef4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "offspring"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.667030900Z"
    }
   },
   "id": "17d1decc062044dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_individual()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.669557800Z"
    }
   },
   "id": "35807f49bf29688f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "create_individual()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.670566300Z"
    }
   },
   "id": "6887e164b9dffe6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-31T07:09:48.671753400Z"
    }
   },
   "id": "951dbf83c1e48ff4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
