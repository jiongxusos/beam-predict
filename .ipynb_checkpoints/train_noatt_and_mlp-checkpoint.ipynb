{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.240565Z",
     "start_time": "2024-10-28T08:36:57.103447200Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyBeamSim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import r2_score\n",
    "from model.old_model import Encoder_Decoder, MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d57134269e306dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.628260700Z",
     "start_time": "2024-10-28T08:36:57.112047600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drift1_len</th>\n",
       "      <th>quad1_len</th>\n",
       "      <th>quad1_gra</th>\n",
       "      <th>drift2_len</th>\n",
       "      <th>quad2_len</th>\n",
       "      <th>quad2_gra</th>\n",
       "      <th>x_avg0</th>\n",
       "      <th>x_avg1</th>\n",
       "      <th>x_avg2</th>\n",
       "      <th>x_avg3</th>\n",
       "      <th>x_avg4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402310</td>\n",
       "      <td>0.450841</td>\n",
       "      <td>-16.332723</td>\n",
       "      <td>0.170125</td>\n",
       "      <td>0.213844</td>\n",
       "      <td>7.026671</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-1.950323e-07</td>\n",
       "      <td>-0.000093</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.237463</td>\n",
       "      <td>0.454075</td>\n",
       "      <td>14.937412</td>\n",
       "      <td>0.273825</td>\n",
       "      <td>0.334553</td>\n",
       "      <td>5.617945</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-4.348649e-06</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.414345</td>\n",
       "      <td>0.177982</td>\n",
       "      <td>19.552067</td>\n",
       "      <td>0.388376</td>\n",
       "      <td>0.442580</td>\n",
       "      <td>2.004069</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-8.071600e-07</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.246283</td>\n",
       "      <td>0.124380</td>\n",
       "      <td>0.320149</td>\n",
       "      <td>0.130190</td>\n",
       "      <td>0.210073</td>\n",
       "      <td>13.761691</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-4.777946e-06</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256067</td>\n",
       "      <td>0.194462</td>\n",
       "      <td>6.097415</td>\n",
       "      <td>0.473669</td>\n",
       "      <td>0.432795</td>\n",
       "      <td>7.627331</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-3.698168e-06</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.247073</td>\n",
       "      <td>0.286787</td>\n",
       "      <td>2.478341</td>\n",
       "      <td>0.375353</td>\n",
       "      <td>0.320700</td>\n",
       "      <td>-13.608154</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2.053298e-06</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.407613</td>\n",
       "      <td>0.432325</td>\n",
       "      <td>4.456587</td>\n",
       "      <td>0.302943</td>\n",
       "      <td>0.444821</td>\n",
       "      <td>4.182542</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-3.394178e-07</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.148527</td>\n",
       "      <td>0.189331</td>\n",
       "      <td>10.690400</td>\n",
       "      <td>0.205502</td>\n",
       "      <td>0.385139</td>\n",
       "      <td>9.790066</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.513054e-06</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.307523</td>\n",
       "      <td>0.318801</td>\n",
       "      <td>2.121998</td>\n",
       "      <td>0.348172</td>\n",
       "      <td>0.262224</td>\n",
       "      <td>-10.475280</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-4.560829e-07</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.166128</td>\n",
       "      <td>0.248988</td>\n",
       "      <td>-2.887280</td>\n",
       "      <td>0.361308</td>\n",
       "      <td>0.429047</td>\n",
       "      <td>14.610668</td>\n",
       "      <td>-2.582750e-09</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-1.217552e-06</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      drift1_len  quad1_len  quad1_gra  drift2_len  quad2_len  quad2_gra  \\\n",
       "0       0.402310   0.450841 -16.332723    0.170125   0.213844   7.026671   \n",
       "1       0.237463   0.454075  14.937412    0.273825   0.334553   5.617945   \n",
       "2       0.414345   0.177982  19.552067    0.388376   0.442580   2.004069   \n",
       "3       0.246283   0.124380   0.320149    0.130190   0.210073  13.761691   \n",
       "4       0.256067   0.194462   6.097415    0.473669   0.432795   7.627331   \n",
       "...          ...        ...        ...         ...        ...        ...   \n",
       "9995    0.247073   0.286787   2.478341    0.375353   0.320700 -13.608154   \n",
       "9996    0.407613   0.432325   4.456587    0.302943   0.444821   4.182542   \n",
       "9997    0.148527   0.189331  10.690400    0.205502   0.385139   9.790066   \n",
       "9998    0.307523   0.318801   2.121998    0.348172   0.262224 -10.475280   \n",
       "9999    0.166128   0.248988  -2.887280    0.361308   0.429047  14.610668   \n",
       "\n",
       "            x_avg0    x_avg1        x_avg2    x_avg3    x_avg4  \n",
       "0    -2.582750e-09  0.000043 -1.950323e-07 -0.000093  0.000375  \n",
       "1    -2.582750e-09  0.000027 -4.348649e-06 -0.000777 -0.000208  \n",
       "2    -2.582750e-09  0.000037 -8.071600e-07  0.000113 -0.000061  \n",
       "3    -2.582750e-09  0.000028 -4.777946e-06 -0.000069 -0.000029  \n",
       "4    -2.582750e-09  0.000029 -3.698168e-06 -0.000044 -0.000005  \n",
       "...            ...       ...           ...       ...       ...  \n",
       "9995 -2.582750e-09  0.000028  2.053298e-06  0.000054 -0.000061  \n",
       "9996 -2.582750e-09  0.000039 -3.394178e-07  0.000015 -0.000064  \n",
       "9997 -2.582750e-09  0.000017  1.513054e-06  0.000009 -0.000010  \n",
       "9998 -2.582750e-09  0.000031 -4.560829e-07 -0.000015 -0.000034  \n",
       "9999 -2.582750e-09  0.000019 -1.217552e-06 -0.000037  0.000011  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data.csv', index_col=0)\n",
    "# df = df[:1000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "301628125f60055d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.628260700Z",
     "start_time": "2024-10-28T08:36:57.186346100Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "hidden_size = 64\n",
    "output_size = 1\n",
    "# output_len = 4\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7873ff8f424e1d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.644565700Z",
     "start_time": "2024-10-28T08:36:57.205518400Z"
    }
   },
   "outputs": [],
   "source": [
    "# last 5 columns as y_true\n",
    "X = df.iloc[:, :-5]\n",
    "y = df.iloc[:, -5:]\n",
    "# transform df into tensor\n",
    "X = torch.Tensor(X.values).unsqueeze(2) # add a dim: input_size\n",
    "y = torch.Tensor(y.values)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49d941c8ecf5fee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.644565700Z",
     "start_time": "2024-10-28T08:36:57.234715300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape: torch.Size([800, 5])\n",
      "X_train.shape: torch.Size([800, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'X_train.shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3703868307437cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.645565400Z",
     "start_time": "2024-10-28T08:36:57.249453Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# generate dataset and dataloader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c22c5c899e24d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.645565400Z",
     "start_time": "2024-10-28T08:36:57.264110700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first y:  tensor([-2.5827e-09,  3.2066e-05, -1.2138e-06, -2.2633e-05,  1.9668e-06])\n"
     ]
    }
   ],
   "source": [
    "first_y = train_dataset[0][1]\n",
    "output_len = first_y.shape[0] - 1\n",
    "print('the first y: ', first_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23e0293cc8575295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.645565400Z",
     "start_time": "2024-10-28T08:36:57.279798500Z"
    }
   },
   "outputs": [],
   "source": [
    "# use mean absolute percent error as criterion\n",
    "def get_mape(tensor_true, tensor_pred):\n",
    "    return torch.mean(torch.abs((tensor_pred - tensor_true) / tensor_true)) * 100\n",
    "# and R2 score\n",
    "\n",
    "def count_all_parameters(model):\n",
    "    return sum(param.numel() for param in model.parameters() if param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f91f02a74e197615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:36:57.645565400Z",
     "start_time": "2024-10-28T08:36:57.294136700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.98\n",
      "MAPE: 6.11%\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.Tensor([100, 200, 300])\n",
    "y_pred = torch.Tensor([110, 190, 310])\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "mape = get_mape(y_true, y_pred)\n",
    "print(f'R^2 Score: {r2:.2f}')\n",
    "print(f'MAPE: {mape:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d28171c2a5a956",
   "metadata": {},
   "source": [
    "model without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96290c3ba15860f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:01.364986800Z",
     "start_time": "2024-10-28T08:36:57.308211800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder_Decoder(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(1, 64, num_layers=3, batch_first=True)\n",
       "    (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Encoder_Decoder(input_size, hidden_size, output_size, output_len, device, num_directions=1, num_layers=3)\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8523314ccd909",
   "metadata": {},
   "source": [
    "### if an inplace operation question, it occurs in  self.decoder(y_pred[:, t, :].unsqueeze(1), hidden_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed911ee4bc8f18ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:27.528979100Z",
     "start_time": "2024-10-28T08:37:01.367080200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training is using cuda\n",
      "epoch1: loss: 0.0846162608\n",
      "epoch2: loss: 0.0040984631\n",
      "epoch3: loss: 0.0007944820\n",
      "epoch4: loss: 0.0002118118\n",
      "epoch5: loss: 0.0000552496\n",
      "epoch6: loss: 0.0000159059\n",
      "epoch7: loss: 0.0000066955\n",
      "epoch8: loss: 0.0000042091\n",
      "epoch9: loss: 0.0000027637\n",
      "epoch10: loss: 0.0000019523\n",
      "epoch11: loss: 0.0000014529\n",
      "epoch12: loss: 0.0000011350\n",
      "epoch13: loss: 0.0000009490\n",
      "epoch14: loss: 0.0000008280\n",
      "epoch15: loss: 0.0000007576\n",
      "epoch16: loss: 0.0000007151\n",
      "epoch17: loss: 0.0000006826\n",
      "epoch18: loss: 0.0000006637\n",
      "epoch19: loss: 0.0000006489\n",
      "epoch20: loss: 0.0000006368\n",
      "epoch21: loss: 0.0000006253\n",
      "epoch22: loss: 0.0000006173\n",
      "epoch23: loss: 0.0000006059\n",
      "epoch24: loss: 0.0000005994\n",
      "epoch25: loss: 0.0000005915\n",
      "epoch26: loss: 0.0000005859\n",
      "epoch27: loss: 0.0000005785\n",
      "epoch28: loss: 0.0000005739\n",
      "epoch29: loss: 0.0000005726\n",
      "epoch30: loss: 0.0000005731\n",
      "epoch31: loss: 0.0000005676\n",
      "epoch32: loss: 0.0000005550\n",
      "epoch33: loss: 0.0000005487\n",
      "epoch34: loss: 0.0000005449\n",
      "epoch35: loss: 0.0000005407\n",
      "epoch36: loss: 0.0000005452\n",
      "epoch37: loss: 0.0000005440\n",
      "epoch38: loss: 0.0000005355\n",
      "epoch39: loss: 0.0000005284\n",
      "epoch40: loss: 0.0000005248\n",
      "epoch41: loss: 0.0000005170\n",
      "epoch42: loss: 0.0000005124\n",
      "epoch43: loss: 0.0000005087\n",
      "epoch44: loss: 0.0000005084\n",
      "epoch45: loss: 0.0000005126\n",
      "epoch46: loss: 0.0000005063\n",
      "epoch47: loss: 0.0000004967\n",
      "epoch48: loss: 0.0000004964\n",
      "epoch49: loss: 0.0000004942\n",
      "epoch50: loss: 0.0000004883\n",
      "epoch51: loss: 0.0000004842\n",
      "epoch52: loss: 0.0000004814\n",
      "epoch53: loss: 0.0000004780\n",
      "epoch54: loss: 0.0000004781\n",
      "epoch55: loss: 0.0000004761\n",
      "epoch56: loss: 0.0000004684\n",
      "epoch57: loss: 0.0000004697\n",
      "epoch58: loss: 0.0000004646\n",
      "epoch59: loss: 0.0000004637\n",
      "epoch60: loss: 0.0000004612\n",
      "epoch61: loss: 0.0000004656\n",
      "epoch62: loss: 0.0000004572\n",
      "epoch63: loss: 0.0000004526\n",
      "epoch64: loss: 0.0000004514\n",
      "epoch65: loss: 0.0000004486\n",
      "epoch66: loss: 0.0000004461\n",
      "epoch67: loss: 0.0000004427\n",
      "epoch68: loss: 0.0000004420\n",
      "epoch69: loss: 0.0000004442\n",
      "epoch70: loss: 0.0000004449\n",
      "epoch71: loss: 0.0000004408\n",
      "epoch72: loss: 0.0000004398\n",
      "epoch73: loss: 0.0000004321\n",
      "epoch74: loss: 0.0000004308\n",
      "epoch75: loss: 0.0000004290\n",
      "epoch76: loss: 0.0000004282\n",
      "epoch77: loss: 0.0000004320\n",
      "epoch78: loss: 0.0000004225\n",
      "epoch79: loss: 0.0000004198\n",
      "epoch80: loss: 0.0000004197\n",
      "epoch81: loss: 0.0000004252\n",
      "epoch82: loss: 0.0000004238\n",
      "epoch83: loss: 0.0000004166\n",
      "epoch84: loss: 0.0000004121\n",
      "epoch85: loss: 0.0000004257\n",
      "epoch86: loss: 0.0000004122\n",
      "epoch87: loss: 0.0000004087\n",
      "epoch88: loss: 0.0000004105\n",
      "epoch89: loss: 0.0000004071\n",
      "epoch90: loss: 0.0000004066\n",
      "epoch91: loss: 0.0000004021\n",
      "epoch92: loss: 0.0000004079\n",
      "epoch93: loss: 0.0000004116\n",
      "epoch94: loss: 0.0000004020\n",
      "epoch95: loss: 0.0000004052\n",
      "epoch96: loss: 0.0000004110\n",
      "epoch97: loss: 0.0000004008\n",
      "epoch98: loss: 0.0000004011\n",
      "epoch99: loss: 0.0000004057\n",
      "epoch100: loss: 0.0000003958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1af98131910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criterion = get_mape\n",
    "model.train_model(train_loader, num_epochs, learning_rate, output_len, method='recurse')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#model.train_model(train_loader, num_epochs, learning_rate, output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847415a1e7a092",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:28.021456600Z",
     "start_time": "2024-10-28T08:37:27.530488500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(6605.96, dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_val_mape(test_loader, output_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34a1f4ec4e150c52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:28.043778Z",
     "start_time": "2024-10-28T08:37:28.017437700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd39cda5db1b4f06",
   "metadata": {},
   "source": [
    "### take some x and y for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b502ffd8b5802db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:28.050450300Z",
     "start_time": "2024-10-28T08:37:28.036968200Z"
    }
   },
   "outputs": [],
   "source": [
    "input = torch.Tensor([0.180365,0.142677,6.547704,0.225119,0.470313,-11.542837, -2.582750e-09])\n",
    "output = torch.Tensor([0.000043,-1.950323e-07,-9.278758e-05,0.000375])\n",
    "input2 = torch.Tensor([[0.180365,0.142677,6.547704,0.225119,0.470313,-11.542837,-2.582750e-09],\n",
    "                        [0.432852,0.169020,6.902478,0.289684,0.324885,-3.967744,-2.582750e-09]])\n",
    "# hidden_decoder = (torch.rand((4, 50, 64)), torch.rand((4, 50, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8544d2f4c85b3f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:28.992527300Z",
     "start_time": "2024-10-28T08:37:28.048448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.043081283569336e-05,\n",
       " 3.7886202335357666e-05,\n",
       " -0.0001120343804359436,\n",
       " -1.0617077350616455e-05]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "output1 = model.predict_cpu(input, output_len)\n",
    "output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9cc5f107b5fdf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:29.011999100Z",
     "start_time": "2024-10-28T08:37:28.991439300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1015.4949)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mape(torch.Tensor(output1), output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1cfe552d7aad095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:30.160408500Z",
     "start_time": "2024-10-28T08:37:29.005255700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0431e-05],\n",
       "         [ 3.7886e-05],\n",
       "         [-1.1203e-04],\n",
       "         [-1.0617e-05]],\n",
       "\n",
       "        [[ 7.4878e-06],\n",
       "         [ 4.1120e-05],\n",
       "         [-1.4634e-04],\n",
       "         [-6.5699e-05]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_cpu(input2, output_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d077079d1fe77b28",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2233877805c722e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:31.169259200Z",
     "start_time": "2024-10-28T08:37:30.161419200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.043081283569336e-05\n",
      "3.7886202335357666e-05\n",
      "-0.0001120343804359436\n",
      "-1.0617077350616455e-05\n"
     ]
    }
   ],
   "source": [
    "x = input[:-1]\n",
    "y = input[-1]\n",
    "output_encoder, hidden_encoder = model.encoder(x.reshape(1, -1, 1))\n",
    "hidden_decoder = hidden_encoder #(1, 1, 1)\n",
    "for i in range(output_len):\n",
    "    output_decoder, hidden_decoder = model.decoder(y.reshape(1, 1, 1), hidden_decoder)\n",
    "    print(output_decoder.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a2502bec03a6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:31.217679700Z",
     "start_time": "2024-10-28T08:37:31.162933500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0617e-05]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76736cd519ca52cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:37:31.471597300Z",
     "start_time": "2024-10-28T08:37:31.178848200Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (3, 50, 64), got [4, 50, 64]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m hidden_decoder \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m64\u001b[39m)), torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m64\u001b[39m)))\n\u001b[1;32m----> 3\u001b[0m output_decoder, hidden_decoder \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_decoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\boluo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\desktop\\GPU-Accelerated-Beam-Simulation-Algorithm-PKU-main\\model\\old_model.py:71\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# transport every shape_change into the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# hidden: output_hidden from encoder\u001b[39;00m\n\u001b[1;32m---> 71\u001b[0m     output, output_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     output_fc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)  \u001b[38;5;66;03m# (batch_size, seq_len, output_size)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_fc, output_hidden\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\boluo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\boluo\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:772\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    770\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    774\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    775\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\boluo\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:698\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    693\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    694\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    695\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    696\u001b[0m                        ):\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 698\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    701\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\boluo\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:231\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    229\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (3, 50, 64), got [4, 50, 64]"
     ]
    }
   ],
   "source": [
    "y = torch.rand((50, 5, 1))\n",
    "hidden_decoder = (torch.rand((4, 50, 64)), torch.rand((4, 50, 64)))\n",
    "output_decoder, hidden_decoder = model.decoder(y, hidden_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580028a817cf4dd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.464360200Z"
    }
   },
   "outputs": [],
   "source": [
    "output_decoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d987e22f0349b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.465697300Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = torch.empty((50, 4, 1))\n",
    "output_decoder, hidden_decoder = model.decoder(y, hidden_decoder) # add two dims\n",
    "output_decoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030e5bfb97ce784",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.470020600Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred[:, 0, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c182366f27dc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.471597300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "mlp = MLP(input_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20ad663edb4300",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.473982900Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp(input[:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6402ab32f7ef0d02",
   "metadata": {},
   "source": [
    "### MLP and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fabb5b2675e13d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T08:38:44.145579Z",
     "start_time": "2024-10-28T08:37:58.468731500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training is using cuda\n",
      "epoch1: loss: 152.7485656738\n",
      "epoch2: loss: 1.0490521193\n",
      "epoch3: loss: 0.2957006991\n",
      "epoch4: loss: 0.0382693633\n",
      "epoch5: loss: 0.0036787097\n",
      "epoch6: loss: 0.0015894551\n",
      "epoch7: loss: 0.0003228539\n",
      "epoch8: loss: 0.0000209621\n",
      "epoch9: loss: 0.0000142063\n",
      "epoch10: loss: 0.0000015991\n",
      "epoch11: loss: 0.0000006727\n",
      "epoch12: loss: 0.0000004266\n",
      "epoch13: loss: 0.0000003628\n",
      "epoch14: loss: 0.0000003546\n",
      "epoch15: loss: 0.0000003536\n",
      "epoch16: loss: 0.0000003532\n",
      "epoch17: loss: 0.0000003536\n",
      "epoch18: loss: 0.0000003540\n",
      "epoch19: loss: 0.0000003540\n",
      "epoch20: loss: 0.0000003537\n",
      "epoch21: loss: 0.0000003547\n",
      "epoch22: loss: 0.0000003535\n",
      "epoch23: loss: 0.0000003531\n",
      "epoch24: loss: 0.0000003532\n",
      "epoch25: loss: 0.0000003532\n",
      "epoch26: loss: 0.0000003532\n",
      "epoch27: loss: 0.0000003532\n",
      "epoch28: loss: 0.0000003533\n",
      "epoch29: loss: 0.0000003535\n",
      "epoch30: loss: 0.0000003548\n",
      "epoch31: loss: 0.0000003532\n",
      "epoch32: loss: 0.0000003539\n",
      "epoch33: loss: 0.0000003537\n",
      "epoch34: loss: 0.0000003535\n",
      "epoch35: loss: 0.0000003538\n",
      "epoch36: loss: 0.0000003532\n",
      "epoch37: loss: 0.0000003536\n",
      "epoch38: loss: 0.0000003544\n",
      "epoch39: loss: 0.0000003531\n",
      "epoch40: loss: 0.0000003538\n",
      "epoch41: loss: 0.0000003536\n",
      "epoch42: loss: 0.0000003535\n",
      "epoch43: loss: 0.0000003536\n",
      "epoch44: loss: 0.0000003538\n",
      "epoch45: loss: 0.0000003538\n",
      "epoch46: loss: 0.0000003538\n",
      "epoch47: loss: 0.0000003545\n",
      "epoch48: loss: 0.0000003547\n",
      "epoch49: loss: 0.0000003535\n",
      "epoch50: loss: 0.0000003533\n",
      "epoch51: loss: 0.0000003532\n",
      "epoch52: loss: 0.0000003537\n",
      "epoch53: loss: 0.0000003531\n",
      "epoch54: loss: 0.0000003542\n",
      "epoch55: loss: 0.0000003539\n",
      "epoch56: loss: 0.0000003539\n",
      "epoch57: loss: 0.0000003540\n",
      "epoch58: loss: 0.0000003551\n",
      "epoch59: loss: 0.0000003543\n",
      "epoch60: loss: 0.0000003536\n",
      "epoch61: loss: 0.0000003540\n",
      "epoch62: loss: 0.0000003533\n",
      "epoch63: loss: 0.0000003539\n",
      "epoch64: loss: 0.0000003539\n",
      "epoch65: loss: 0.0000003551\n",
      "epoch66: loss: 0.0000003542\n",
      "epoch67: loss: 0.0000003541\n",
      "epoch68: loss: 0.0000003540\n",
      "epoch69: loss: 0.0000003535\n",
      "epoch70: loss: 0.0000003535\n",
      "epoch71: loss: 0.0000003544\n",
      "epoch72: loss: 0.0000003570\n",
      "epoch73: loss: 0.0000003540\n",
      "epoch74: loss: 0.0000003534\n",
      "epoch75: loss: 0.0000003553\n",
      "epoch76: loss: 0.0000003547\n",
      "epoch77: loss: 0.0000003554\n",
      "epoch78: loss: 0.0000003560\n",
      "epoch79: loss: 0.0000003561\n",
      "epoch80: loss: 0.0000003569\n",
      "epoch81: loss: 0.0000003596\n",
      "epoch82: loss: 0.0000003543\n",
      "epoch83: loss: 0.0000003551\n",
      "epoch84: loss: 0.0000003564\n",
      "epoch85: loss: 0.0000003544\n",
      "epoch86: loss: 0.0000003549\n",
      "epoch87: loss: 0.0000003545\n",
      "epoch88: loss: 0.0000003545\n",
      "epoch89: loss: 0.0000003541\n",
      "epoch90: loss: 0.0000003583\n",
      "epoch91: loss: 0.0000003585\n",
      "epoch92: loss: 0.0000003553\n",
      "epoch93: loss: 0.0000003558\n",
      "epoch94: loss: 0.0000003548\n",
      "epoch95: loss: 0.0000003541\n",
      "epoch96: loss: 0.0000003548\n",
      "epoch97: loss: 0.0000003548\n",
      "epoch98: loss: 0.0000003552\n",
      "epoch99: loss: 0.0000003542\n",
      "epoch100: loss: 0.0000003543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlp = MLP(input_size=6)\n",
    "optimizer = optim.Adam(mlp.parameters(), lr=0.1)\n",
    "mlp.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch == 0:\n",
    "        print(f'the training is using {device}')\n",
    "    mlp.train()\n",
    "    total_loss = 0\n",
    "    for X, y in train_loader:\n",
    "        X = X.squeeze(2).to(device)   #(50, 6)\n",
    "        y = y[:, 1:].to(device) # two-dim tensor (50, 4)\n",
    "        y_pred = mlp(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        total_loss += loss\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    print(f'epoch{epoch+1}: loss: {total_loss:.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f41e11dc89881",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.477452100Z"
    }
   },
   "outputs": [],
   "source": [
    "mlp.to('cpu')\n",
    "mlp(input[:-1]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3b28017d358ce",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-28T08:37:31.478843800Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
